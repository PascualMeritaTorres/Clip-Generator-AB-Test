"""
Module to generate and load topics from transcription using Fal AI.
The module uses fal_client to generate topics and saves the topics into a JSON file.
Other modules (e.g. add_images.py and add_sound_effects.py) can load the topics from this file.
"""

from typing import List, Dict
import json
import os
import time
import logging
import fal_client  # Ensure correct installation via pipenv install fal-client

# Logging configuration for generate_topics
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# Global filter to suppress any log containing "HTTP Request:" in its message.
class SuppressHttpRequestFilter(logging.Filter):
    def filter(self, record: logging.LogRecord) -> bool:
         return "HTTP Request:" not in record.getMessage()

# Add the filter to the root logger so it applies to all log messages.
logging.getLogger().addFilter(SuppressHttpRequestFilter())

# Additionally, ensure that fal_client's logger uses WARNING level.
logging.getLogger("fal_client").setLevel(logging.WARNING)

def generate_topics(transcription: str, output_file: str = "identified_topics.json") -> Dict[str, List[str]]:
    """
    Generate topics from a full transcription using fal_client (LLM) and save them into a JSON file.

    The returned JSON is a dictionary where each key is a topic name and the value is
    a list of words (strings) that belong to that topic.
    
    Args:
        transcription (str): Full transcription text.
        output_file (str): Path to output JSON file.
        
    Returns:
        Dict[str, List[str]]: Dictionary mapping topic names to list of words.
        
    Raises:
        AssertionError: If LLM response is invalid.
        RuntimeError: If multiple attempts fail.
    """
    base_prompt = f"""
Split this text into sequential topics, where each topic represents a distinct concept or idea that is being talked about.
The words in each topic must appear in the exact same order as in the original text.
When concatenating all the words from all topics in order, it must reconstruct the original text exactly.

Rules:
1. Each topic should be a SINGLE descriptive word capturing its meaning.
2. The words in each topic must be taken sequentially from the text.
3. Every word from the original text must be included exactly once.
4. The order of topics must match the text flow.
5. Do not add, remove, or modify words.

Return ONLY a JSON where:
- Each key is a topic name.
- Each value is a list of the exact words from that section of text.

Example:
Text: "What is the one spy trick you would teach everyone"
Output: {{"spy": ["What", "is", "the", "one", "spy", "trick", "you", "would", "teach", "everyone"]}}

Text: {transcription}
    """
    def on_queue_update(update: fal_client.InProgress) -> None:
        """Callback to log progress of image generation.
        
        Disabled logging to avoid printing HTTP request logs.
        """
        pass

    max_attempts = 3
    for attempt in range(max_attempts):
        logging.info(f"generate_topics: Attempt {attempt + 1}")
        try:
            result = fal_client.subscribe(
                "fal-ai/any-llm",
                arguments={
                    "model": "anthropic/claude-3.5-sonnet",
                    "prompt": base_prompt + "\n\nRemember: Output only valid JSON." if attempt > 0 else base_prompt
                },
                with_logs=True,
                on_queue_update=on_queue_update
            )
            result_json = json.loads(result["output"])
            assert isinstance(result_json, dict), "LLM response must be a dictionary"
            # Save the topics dictionary to the output file
            with open(output_file, 'w') as f:
                json.dump(result_json, f, indent=2)
            logging.info(f"generate_topics: Topics generated and saved to {output_file}")
            return result_json
        except Exception as e:
            logging.error(f"generate_topics: Attempt {attempt + 1} failed with error: {e}")
            if attempt == max_attempts - 1:
                raise RuntimeError(f"Failed to generate topics after {max_attempts} attempts") from e
    raise RuntimeError("generate_topics: Unexpected error")

def load_topics(output_file: str = "identified_topics.json") -> Dict[str, List[str]]:
    """
    Load topics from a given JSON file generated by generate_topics.
    
    Args:
        output_file (str): Path to JSON file containing topics.
        
    Returns:
        Dict[str, List[str]]: Dictionary mapping topic names to list of words.
    """
    assert os.path.exists(output_file), f"Topics file not found: {output_file}"
    with open(output_file, 'r') as f:
        topics_data = json.load(f)
    assert isinstance(topics_data, dict), "Topics file must contain a dictionary"
    return topics_data

if __name__ == "__main__":
    import sys
    if len(sys.argv) != 2:
        print("Usage: python generate_topics.py <transcription_file.jsonl>")
        sys.exit(1)
    transcription_file = sys.argv[1]
    # Read transcription from file
    assert os.path.exists(transcription_file), f"Transcription file not found: {transcription_file}"
    with open(transcription_file, 'r') as f:
        data = json.load(f)
    assert isinstance(data, dict) and 'text' in data, "Invalid transcription JSON file. Expected a dict with a 'text' key."
    transcription_text = data['text']
    # Generate topics and save to identified_topics.json
    generate_topics(transcription_text) 